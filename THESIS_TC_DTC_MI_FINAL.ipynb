{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmC-r6bE9jy2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from math import log2\n",
        "import pandas as pd\n",
        "from matplotlib.collections import LineCollection\n",
        "import matplotlib.patches as mpatches\n",
        "from itertools import product\n",
        "\n",
        "\n",
        "\n",
        "s=1985"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CREATING METRICS"
      ],
      "metadata": {
        "id": "2XmNHVjNZLd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def entropy(X):\n",
        "\n",
        "  # Count the occurrences of each unique value in the sample\n",
        "  unique, counts = np.unique(X, return_counts=True)\n",
        "\n",
        "  # Calculate the probabilities of each unique value\n",
        "  p = counts / len(X)\n",
        "\n",
        "  # Handle zero probabilities (add small value for numerical stability)\n",
        "  p[p == 0] = np.finfo(float).eps\n",
        "\n",
        "  # Calculate the entropy\n",
        "  return -np.sum(p * np.log2(p))  # Base 2 logarithm for binary entropy\n",
        "\n",
        "# Example usage\n",
        "size=1000\n",
        "r=1000\n",
        "\n",
        "X1 = np.random.randint(0, r, size)\n",
        "entropy_value = entropy(X1)\n",
        "print(f\"The entropy of the sample is: {entropy_value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_4uSpWUKfbr",
        "outputId": "eab557ab-4b3d-419d-d283-368c1c92b8ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The entropy of the sample is: 9.116178169653605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def entropy_continuous(X, num_bins=10):\n",
        "    \"\"\"Estimates the differential entropy of a continuous variable using binning.\n",
        "\n",
        "    Args:\n",
        "        X: An array-like object containing the data samples.\n",
        "        num_bins: Number of bins to use for discretization.\n",
        "\n",
        "    Returns:\n",
        "        float: The estimated differential entropy.\n",
        "    \"\"\"\n",
        "\n",
        "    if num_bins <= 0:\n",
        "       raise ValueError(\"num_bins must be a positive integer\")\n",
        "\n",
        "    # 1. Find value range and create bins\n",
        "    data_min, data_max = X.min(), X.max()\n",
        "    if data_max - data_min == 0:  # All data has the same value\n",
        "        return 0.0\n",
        "\n",
        "    bin_width = (data_max - data_min) / num_bins\n",
        "    bins = np.arange(data_min, data_max + bin_width, bin_width)\n",
        "\n",
        "    # 2. Calculate bin counts (approximate probability)\n",
        "    bin_counts = np.histogram(X, bins=bins)[0]\n",
        "    p = bin_counts / len(X)\n",
        "\n",
        "    # 3. Handle zero probabilities and calculate entropy\n",
        "    p[p == 0] = np.finfo(float).eps  # Add tiny value for stability\n",
        "    entropy = -np.sum(p * np.log2(p))\n",
        "\n",
        "    return entropy\n"
      ],
      "metadata": {
        "id": "Oid8BOlzwWz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def probability(X):\n",
        "  counts={}\n",
        "  total=len(X)\n",
        "  for x in X:\n",
        "    counts[x]=counts.get(x, 0) + 1\n",
        "\n",
        "  probs={count:x /total for count,x in counts.items()}\n",
        "  return probs\n",
        "\n"
      ],
      "metadata": {
        "id": "0djk5RUcBWhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def joint_probability(X, Y):\n",
        "    # Create a dictionary to count occurrences of each pair (x, y)\n",
        "    pair_counts = {}\n",
        "    total_pairs = len(X)\n",
        "\n",
        "    for x, y in zip(X, Y):\n",
        "        pair = (x, y)\n",
        "        pair_counts[pair] = pair_counts.get(pair, 0) + 1\n",
        "\n",
        "    # Calculate the joint probability of each (x, y) pair\n",
        "    joint_probs = {pair: count / total_pairs for pair, count in pair_counts.items()}\n",
        "\n",
        "    return joint_probs\n"
      ],
      "metadata": {
        "id": "v-LOPE9kBzG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def joint_probability3(X, Y, Z):\n",
        "    # Create a dictionary to count occurrences of each triple (x, y, z)\n",
        "    triple_counts = {}\n",
        "    total_triples = len(X)\n",
        "\n",
        "    for x, y, z in zip(X, Y, Z):\n",
        "        triple = (x, y, z)\n",
        "        triple_counts[triple] = triple_counts.get(triple, 0) + 1\n",
        "\n",
        "    # Calculate the joint probability of each (x, y, z) triple\n",
        "    joint_probs = {triple: count / total_triples for triple, count in triple_counts.items()}\n",
        "\n",
        "    return joint_probs"
      ],
      "metadata": {
        "id": "QRu0mCwkJUn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def probability_of_x_given_y(X, Y):\n",
        "    counts = {}\n",
        "    # Create an empty dictionary to store counts of x for each unique y\n",
        "\n",
        "    for x, y in zip(X, Y):\n",
        "        if y not in counts:\n",
        "            counts[y] = {}\n",
        "            # If y is not already a key in counts, initialize it with an empty dictionary\n",
        "\n",
        "        if x not in counts[y]:\n",
        "            counts[y][x] = 0\n",
        "            # If x is not already a key in counts[y], initialize it with a count of 0\n",
        "\n",
        "        counts[y][x] += 1\n",
        "        # Increment the count of x for the corresponding y\n",
        "\n",
        "    probabilities = {}\n",
        "    # Create a dictionary to store probabilities\n",
        "\n",
        "    for y, x_counts in counts.items():\n",
        "        total_count = sum(x_counts.values())\n",
        "        # Calculate the total count of x values for a particular y\n",
        "\n",
        "        probabilities[y] = {x: count / total_count for x, count in x_counts.items()}\n",
        "        # Calculate the probability of each x value given a specific y value.\n",
        "        # This is done by dividing the count of each x value by the total count of x values for that y.\n",
        "\n",
        "    return probabilities\n",
        "\n"
      ],
      "metadata": {
        "id": "J7ecMgdC95mY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def conditional_entropy(X, Y):\n",
        "    joint_probs = joint_probability(X, Y)\n",
        "    prob_y = probability(Y)\n",
        "    entropy = 0.0\n",
        "    for key, value in joint_probs.items():\n",
        "      py=prob_y[key[1]]\n",
        "      entropy-=value*math.log(value/py,2)\n",
        "    return entropy\n"
      ],
      "metadata": {
        "id": "TYtO-HYyAGd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def joint_entropy(X, Y):\n",
        "    joint_probs = joint_probability(X, Y)\n",
        "    entropy = 0.0\n",
        "    for key, value in joint_probs.items():\n",
        "      entropy-=value*math.log(value,2)\n",
        "    return entropy\n"
      ],
      "metadata": {
        "id": "ygkeEd1IG0Wu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def joint_entropy3(X,Y,Z):\n",
        "    p_xyz=joint_probability3(X,Y,Z)\n",
        "    entropy = 0.0\n",
        "    for prob in p_xyz.values():\n",
        "        entropy -= prob * math.log2(prob)\n",
        "    return entropy"
      ],
      "metadata": {
        "id": "uqtEmwecJhP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mutual_information(X,Y):\n",
        "  return entropy(X)-conditional_entropy(X,Y)\n"
      ],
      "metadata": {
        "id": "Hdeqjpo8Hmth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mutual_information3(X,Y,Z):\n",
        "  res=entropy(X)+entropy(Y)+entropy(Z)-joint_entropy(X,Y)-joint_entropy(X,Z)-joint_entropy(Y,Z)+joint_entropy3(X,Y,Z)\n",
        "  return -res"
      ],
      "metadata": {
        "id": "uRYF0WBSJ3M7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conditional_mutual_information(X,Y,Z):\n",
        "  return -(mutual_information(X,Y)-mutual_information(X,Z)-mutual_information(Y,Z)-mutual_information3(X,Y,Z))"
      ],
      "metadata": {
        "id": "u0tSrpLQKu1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mutual_informationX1X2Y(X1, X2, Y):\n",
        "    res = 0\n",
        "    PJ = joint_probability_List(X1, X2, Y)\n",
        "    PX1X2 = joint_probability_List(X1, X2)\n",
        "    PY = probability(Y)\n",
        "\n",
        "    for x1, x2, y in set(product(X1, X2, Y)):\n",
        "        pj = PJ.get((x1, x2, y), 0.0)\n",
        "        py = PY.get(y, 0.0)\n",
        "        px1x2 = PX1X2.get((x1, x2), 0.0)\n",
        "        if pj != 0 and py != 0 and px1x2 != 0:\n",
        "            res += pj * log2(pj/(py * px1x2))\n",
        "    return res"
      ],
      "metadata": {
        "id": "1Fq742KzAUkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def local_mutual_informationX1X2Y(X1,X2,Y, x1,x2,y):\n",
        "  res=0\n",
        "  PJ=joint_probability_List(X1,X2,Y)\n",
        "  PX1X2=joint_probability_List(X1,X2)\n",
        "  PY=probability(Y)\n",
        "  pj=PJ.get((x1,x2,y), 0.0)\n",
        "  py=PY.get(y, 0.0)\n",
        "  px1x2=PX1X2.get((x1,x2), 0.0)\n",
        "  if pj != 0 and py != 0 and px1x2 != 0: return log2(pj/(py*px1x2))\n",
        "  return 0\n"
      ],
      "metadata": {
        "id": "DIwerx367tJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def joint_probability_List(*args):\n",
        "    counts = {}\n",
        "    total_combos = len(args[0])\n",
        "\n",
        "    for tup in list(zip(*args)):\n",
        "       key_tuple = tuple(tup)\n",
        "       counts[key_tuple] = counts.get(key_tuple, 0) + 1\n",
        "    joint_probs = {tup: count / total_combos for tup, count in counts.items()}\n",
        "\n",
        "    return joint_probs"
      ],
      "metadata": {
        "id": "wN5b5eJiNp32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def joint_probability_List_continuous(*args, num_bins=10):\n",
        "    \"\"\"Calculates the approximate joint probability for continuous variables using binning,\n",
        "       with enhancements to handle data ranges equal to zero.\n",
        "\n",
        "    Args:\n",
        "        *args:  Arrays of continuous values representing the different variables.\n",
        "        num_bins: Number of bins to use for each variable.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary where keys are tuples representing bin combinations\n",
        "              and values are the approximate joint probabilities.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Find value ranges for binning\n",
        "    min_values = [np.min(data) for data in args]\n",
        "    max_values = [np.max(data) for data in args]\n",
        "    bin_widths = [(max_val - min_val) / num_bins for max_val, min_val in zip(max_values, min_values)]\n",
        "\n",
        "    # 2. Assign values to bins, handling zero-range cases\n",
        "    binned_data = []\n",
        "    for data, min_val, max_val, width in zip(args, min_values, max_values, bin_widths):\n",
        "        if max_val - min_val == 0:  # Zero range detected\n",
        "          if np.all(data == data[0]):  # All values are the same\n",
        "            binned_data.append(np.zeros_like(data))  # Assign all to a single bin\n",
        "        else:\n",
        "          binned_data.append(np.digitize(data, np.arange(min_val, max_val + width, width)))\n",
        "\n",
        "    # 3. Use original logic for calculating joint probability on binned (now discrete) data\n",
        "    counts = {}\n",
        "    total_combos = len(binned_data[0])\n",
        "\n",
        "    for tup in list(zip(*binned_data)):\n",
        "        key_tuple = tuple(tup)\n",
        "        counts[key_tuple] = counts.get(key_tuple, 0) + 1\n",
        "    joint_probs = {tup: count / total_combos for tup, count in counts.items()}\n",
        "\n",
        "    return joint_probs\n"
      ],
      "metadata": {
        "id": "tCBlpL7xvMFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def joint_entropy_List(*args):\n",
        "  jp=joint_probability_List(*args)\n",
        "  entropy = 0.0\n",
        "  for prob in jp.values():\n",
        "    entropy -= prob * math.log2(prob)\n",
        "  return entropy"
      ],
      "metadata": {
        "id": "QQ3tWCwJLMSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def joint_entropy_List_continuous(*args):\n",
        "  jp=joint_probability_List_continuous(*args)\n",
        "  entropy = 0.0\n",
        "  for prob in jp.values():\n",
        "    entropy -= prob * math.log2(prob)\n",
        "  return entropy"
      ],
      "metadata": {
        "id": "TeLjfenKvRfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conditional_entropy_List(X, *args):\n",
        "    joint_probs = joint_probability_List(X, *args)\n",
        "    prob_arg = joint_probability_List(*args)\n",
        "    entropy = 0.0\n",
        "    for key, value in joint_probs.items():\n",
        "      parg=prob_arg[key[1:]]\n",
        "      entropy-=value*math.log(value/parg,2)\n",
        "    return entropy"
      ],
      "metadata": {
        "id": "MwPtbZJ3WBCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conditional_entropy_List_continuous(X, *args):\n",
        "    joint_probs = joint_probability_List_continuous(X, *args)\n",
        "    prob_arg = joint_probability_List_continuous(*args)\n",
        "    entropy = 0.0\n",
        "    for key, value in joint_probs.items():\n",
        "      parg=prob_arg[key[1:]]\n",
        "      entropy-=value*math.log(value/parg,2)\n",
        "    return entropy"
      ],
      "metadata": {
        "id": "MRuZUWPhvp0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def TC_List(*args):\n",
        "  sum=0\n",
        "  for X in args:\n",
        "    sum+=entropy(X)\n",
        "  return sum-joint_entropy_List(*args)"
      ],
      "metadata": {
        "id": "P6YPxf8ZW23z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def TC_List_continuous(*args):\n",
        "  sum=0\n",
        "  for X in args:\n",
        "    sum+=entropy_continuous(X)\n",
        "  return sum-joint_entropy_List_continuous(*args)"
      ],
      "metadata": {
        "id": "n1-57Xbzv6U7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DTC_List(*args):\n",
        "  sum=0\n",
        "  for i, arg in enumerate(args):\n",
        "        other_args = args[:i] + args[i+1:]\n",
        "        sum+=conditional_entropy_List(arg,*other_args)\n",
        "  return joint_entropy_List(*args)-sum"
      ],
      "metadata": {
        "id": "AAr5oYSJUGUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DTC_List_continuous(*args):\n",
        "  sum=0\n",
        "  for i, arg in enumerate(args):\n",
        "        other_args = args[:i] + args[i+1:]\n",
        "        sum+=conditional_entropy_List_continuous(arg,*other_args)\n",
        "  return joint_entropy_List_continuous(*args)-sum"
      ],
      "metadata": {
        "id": "NnkBLHrsw4Dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def O_information(*args):\n",
        "  return TC_List(*args)-DTC_List(*args)"
      ],
      "metadata": {
        "id": "hhGevr5Cc1eT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def O_information_continuous(*args):\n",
        "  return TC_List_continuous(*args)-DTC_List_continuous(*args)"
      ],
      "metadata": {
        "id": "dLLhxQA5WIwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPACT OF CORRELATION ON TC and DTC"
      ],
      "metadata": {
        "id": "fLPij8yKWSCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_correlated_datasets(n, r, s, c):\n",
        "    \"\"\"\n",
        "    Creates two datasets with a given correlation.\n",
        "\n",
        "    Args:\n",
        "        n (int): Number of elements in each dataset.\n",
        "        r (int): Range of the numbers in the dataset (0 to r).\n",
        "        s (int): Seed for the random number generator.\n",
        "        c (float): The desired correlation coefficient (-1 to 1).\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the two correlated datasets as NumPy arrays.\n",
        "    \"\"\"\n",
        "\n",
        "    np.random.seed(s)\n",
        "\n",
        "    # Ensure correlation coefficient is within valid range\n",
        "    if not -1 <= c <= 1:\n",
        "        raise ValueError(\"Correlation coefficient 'c' must be between -1 and 1.\")\n",
        "\n",
        "    # Generate a base dataset\n",
        "    x = np.random.randint(0, r + 1, size=n)\n",
        "\n",
        "    # Create a correlated dataset based on the desired correlation\n",
        "    if c == 0:\n",
        "        # No correlation, just generate another independent dataset\n",
        "        y = np.random.randint(0, r + 1, size=n)\n",
        "    elif c == 1:\n",
        "        y = x\n",
        "    else:\n",
        "        # Calculate the required standard deviation for the correlated data\n",
        "        sigma_y = np.std(x) * np.sqrt(1 - c**2)\n",
        "\n",
        "        # Generate correlated noise\n",
        "        noise = np.random.normal(scale=sigma_y, size=n)\n",
        "\n",
        "        # Create the correlated dataset\n",
        "        y = c * x + noise\n",
        "        y = np.round(y).astype(int)\n",
        "        y = np.clip(y, 0, r)\n",
        "\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "DWYxYNnwa-F2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_correlated_binary_datasets(n, s, c):\n",
        "    np.random.seed(s)\n",
        "\n",
        "    # Generate random binary dataset x\n",
        "    x = np.random.binomial(1, 0.5, n)\n",
        "\n",
        "    # Generate random noise for y\n",
        "    noise = np.random.binomial(1, 0.5, n)\n",
        "\n",
        "    # Calculate y based on correlation c with x\n",
        "    y = np.where(noise, x, 1 - x)\n",
        "\n",
        "    # Introduce correlation between x and y\n",
        "    if c != 0:\n",
        "        cov_matrix = np.array([[1, c], [c, 1]])\n",
        "        x_y = np.random.multivariate_normal([0, 0], cov_matrix, size=n).T\n",
        "        x, y = np.where(x_y > 0, 1, 0)\n",
        "\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "imjMq48VwAQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GENEREREN VAN DATA"
      ],
      "metadata": {
        "id": "PTKB2Xkr6yFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_correlation_table_weights(n, t_c, t_w, r,s):\n",
        "    \"\"\"\n",
        "    Generates a table of Dual Total Correlations for different correlation coefficients.\n",
        "\n",
        "    Args:\n",
        "        n (int): Number of samples in X1 and X2.\n",
        "        t_c (int): Number of correlation values\n",
        "        t_w (int): Number of\n",
        "        r (int): Range for the values in X1 and X2 (0 to r).\n",
        "        s=seed\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame: A table containing correlation coefficients, X1-X2\n",
        "                          correlations, and Dual Total Correlations.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    corrs = np.linspace(0, 1, t_c)  # Uniformly spaced correlation coefficients\n",
        "    weights= np.linspace(0, 1, t_w)\n",
        "    results = []\n",
        "    for w_AND in weights:\n",
        "      for corr in corrs:\n",
        "        X1, X2 = create_correlated_datasets(n, r, s, corr)\n",
        "        Y=w_AND*np.logical_and(X1,X2)+(1-w_AND)*np.logical_xor(X1,X2)#+np.random.standard_normal()\n",
        "        Y=Y.round()\n",
        "        #Y=np.clip(Y, 0, 1).round()\n",
        "\n",
        "        true_corr = np.corrcoef(X1, X2)[0, 1]  # True correlation between X1 and X2\n",
        "        X1_Y_corr=np.corrcoef(X1, Y)[0, 1]\n",
        "        X2_Y_corr=np.corrcoef(X2, Y)[0, 1]\n",
        "        dtc = DTC_List_continuous(X1, X2, Y)\n",
        "        tc= TC_List_continuous(X1,X2,Y)\n",
        "\n",
        "        results.append({'w_AND': w_AND, 'X1-X2 Correlation': true_corr, 'X1-Y Correlation': X1_Y_corr,'X2-Y Correlation': X2_Y_corr,'DTC': dtc, 'TC': tc, 'OINF': tc-dtc})\n",
        "    df = pd.DataFrame(results)\n",
        "\n",
        "\n",
        "\n",
        "    return pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "V4KHWbv7TI0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_correlation_table_function(n, t_c, r,s):\n",
        "    \"\"\"\n",
        "    Generates a table of Dual Total Correlations for different correlation coefficients.\n",
        "\n",
        "    Args:\n",
        "        n (int): Number of samples in X1 and X2.\n",
        "        t_c (int): Number of correlation values\n",
        "        r (int): Range for the values in X1 and X2 (0 to r).\n",
        "        s=seed\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame: A table containing correlation coefficients, X1-X2\n",
        "                          correlations, and Dual Total Correlations.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    corrs = np.linspace(0, 1, t_c)  # Uniformly spaced correlation coefficients\n",
        "    results = []\n",
        "    for corr in corrs:\n",
        "        X1, X2 = create_correlated_datasets(n, r, s, corr)\n",
        "        Y=np.logical_and(X1,X2)\n",
        "        Y=np.logical_xor(X1,X2)\n",
        "        Y=np.random.randint(0, r + 1, size=n)\n",
        "        Y=Y.round()\n",
        "        #Y=np.clip(Y, 0, 1).round()\n",
        "\n",
        "        true_corr = np.corrcoef(X1, X2)[0, 1]  # True correlation between X1 and X2\n",
        "        X1_Y_corr=np.corrcoef(X1, Y)[0, 1]\n",
        "        X2_Y_corr=np.corrcoef(X2, Y)[0, 1]\n",
        "        dtc = DTC_List_continuous(X1, X2, Y)\n",
        "        tc= TC_List_continuous(X1,X2,Y)\n",
        "        results.append({'X1-X2 Correlation': true_corr, 'X1-Y Correlation': X1_Y_corr,'X2-Y Correlation': X2_Y_corr,'DTC': dtc, 'TC': tc, 'OINF': tc-dtc})\n",
        "    df = pd.DataFrame(results)\n",
        "\n",
        "    return pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "By__nNHv36uB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_correlation_vs_dtc_tc_oinf(df, figsize=(15, 4)):\n",
        "    \"\"\"\n",
        "    Creates plots with two subplots: 'X1-X2 Correlation' vs 'DTC' and\n",
        "    'X1-X2 Correlation' vs 'TC' for each w_AND value. Ensures shared y-axis range.\n",
        "\n",
        "    Args:\n",
        "        df (pandas.DataFrame): The DataFrame containing results.\n",
        "        figsize (tuple, optional): The size of each figure. Defaults to (10, 4).\n",
        "    \"\"\"\n",
        "    ylim_min = -1\n",
        "    ylim_max = 3\n",
        "    for i, group in df.groupby('w_AND'):\n",
        "        w_AND = group['w_AND'].iloc[0]\n",
        "\n",
        "        # Create figure and subplots\n",
        "        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=figsize)\n",
        "\n",
        "        # Plot 'X1-X2 Correlation' vs 'DTC'\n",
        "        ax1.scatter(group['X1-X2 Correlation'], group['DTC'])\n",
        "        ax1.set_xlabel('X1-X2 Correlation')\n",
        "        ax1.set_ylabel('DTC')\n",
        "        ax1.set_title(f'DTC: w_AND = {w_AND:.2f}')\n",
        "\n",
        "        # Plot 'X1-X2 Correlation' vs 'TC'\n",
        "        ax2.scatter(group['X1-X2 Correlation'], group['TC'])\n",
        "        ax2.set_xlabel('X1-X2 Correlation')\n",
        "        ax2.set_ylabel('TC')\n",
        "        ax2.set_title(f'TC: w_AND = {w_AND:.2f}')\n",
        "\n",
        "        # Plot 'X1-X2 Correlation' vs 'O-inf'\n",
        "        ax3.scatter(group['X1-X2 Correlation'], group['OINF'])\n",
        "        ax3.set_xlabel('X1-X2 Correlation')\n",
        "        ax3.set_ylabel('OINF')\n",
        "        ax3.set_title(f'OINF: w_AND = {w_AND:.2f}')\n",
        "\n",
        "        # Set the same y-axis range for both subplots\n",
        "        ax1.set_ylim(ylim_min, ylim_max)\n",
        "        ax2.set_ylim(ylim_min, ylim_max)\n",
        "        ax3.set_ylim(ylim_min, ylim_max)\n",
        "\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "vTmN8La8xhI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_correlation_vs_dtc_tc_oinf_function(df, figsize=(15, 4)):\n",
        "    \"\"\"\n",
        "    Creates plots with two subplots: 'X1-X2 Correlation' vs 'DTC' and\n",
        "    'X1-X2 Correlation' vs 'TC' for each w_AND value. Ensures shared y-axis range.\n",
        "\n",
        "    Args:\n",
        "        df (pandas.DataFrame): The DataFrame containing results.\n",
        "        figsize (tuple, optional): The size of each figure. Defaults to (10, 4).\n",
        "    \"\"\"\n",
        "    ylim_min = -1\n",
        "    ylim_max = 3\n",
        "    # Create figure and subplots\n",
        "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=figsize)\n",
        "\n",
        "    # Plot 'X1-X2 Correlation' vs 'DTC'\n",
        "    ax1.scatter(df['X1-X2 Correlation'], df['DTC'])\n",
        "    ax1.set_xlabel('X1-X2 Correlation')\n",
        "    ax1.set_ylabel('DTC')\n",
        "    ax1.set_title(f'DTC: w_AND = {w_AND:.2f}')\n",
        "\n",
        "    # Plot 'X1-X2 Correlation' vs 'TC'\n",
        "    ax2.scatter(df['X1-X2 Correlation'], df['TC'])\n",
        "    ax2.set_xlabel('X1-X2 Correlation')\n",
        "    ax2.set_ylabel('TC')\n",
        "    ax2.set_title(f'TC: w_AND = {w_AND:.2f}')\n",
        "\n",
        "    # Plot 'X1-X2 Correlation' vs 'O-inf'\n",
        "    ax3.scatter(df['X1-X2 Correlation'], df['OINF'])\n",
        "    ax3.set_xlabel('X1-X2 Correlation')\n",
        "    ax3.set_ylabel('OINF')\n",
        "    ax3.set_title(f'OINF: w_AND = {w_AND:.2f}')\n",
        "\n",
        "    # Set the same y-axis range for both subplots\n",
        "    ax1.set_ylim(ylim_min, ylim_max)\n",
        "    ax2.set_ylim(ylim_min, ylim_max)\n",
        "    ax3.set_ylim(ylim_min, ylim_max)\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "D0MeHYnd5HhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generate_correlation_table_function(1000, 20, 1,s)"
      ],
      "metadata": {
        "id": "2Lhh6yqdfvAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOCAL MEASUREMENTS\n"
      ],
      "metadata": {
        "id": "zfigokUI7w2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def local_TC(X,Y,Z):\n",
        "  pX=probability(X)\n",
        "  pY=probability(Y)\n",
        "  pZ=probability(Z)\n",
        "  pXYZ=joint_probability_List(X,Y,Z)\n",
        "  result=[]\n",
        "  for x,y,z in zip(X,Y,Z):\n",
        "    i=-(np.log2(pX.get(x))+np.log2(pY.get(y))+np.log2(pZ.get(z)))+np.log2(pXYZ.get((x,y,z)))\n",
        "    result.append(i)\n",
        "  return result\n"
      ],
      "metadata": {
        "id": "koZop2-0736-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def local_DTC(X,Y,Z):\n",
        "  pXYZ=joint_probability_List(X,Y,Z)\n",
        "  result=[]\n",
        "  for x,y,z in zip(X,Y,Z):\n",
        "    i=-np.log2(pXYZ.get((x,y,z)))+np.log2(conditional_probability(X,Y,Z,x,y,z))+np.log2(conditional_probability(Y,Z,X,y,z,x))+np.log2(conditional_probability(Z,X,Y,z,x,y))\n",
        "    result.append(i)\n",
        "  return result"
      ],
      "metadata": {
        "id": "pBn1t8mBD5RA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def local_mutual_informationX1X2Y(X1,X2,Y, x1,x2,y):\n",
        "  PJ=joint_probability_List(X1,X2,Y)\n",
        "  PX1X2=joint_probability_List(X1,X2)\n",
        "  PY=probability(Y)\n",
        "  pj=PJ.get((x1,x2,y), 0.0)\n",
        "  py=PY.get(y, 0.0)\n",
        "  px1x2=PX1X2.get((x1,x2), 0.0)\n",
        "  if pj != 0 and py != 0 and px1x2 != 0: return log2(pj/(py*px1x2))\n",
        "  return 0\n"
      ],
      "metadata": {
        "id": "KLvAL0_ktjhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def local_mutual_X1X2Y(X1,X2,Y):\n",
        "  result=[]\n",
        "  PJ=joint_probability_List(X1,X2,Y)\n",
        "  PX1X2=joint_probability_List(X1,X2)\n",
        "  PY=probability(Y)\n",
        "  for x1,x2,y in zip(X1,X2,Y):\n",
        "    pj=PJ.get((x1,x2,y), 0.0)\n",
        "    py=PY.get(y, 0.0)\n",
        "    px1x2=PX1X2.get((x1,x2), 0.0)\n",
        "    if pj != 0 and py != 0 and px1x2 != 0:\n",
        "      i= log2(pj/(py*px1x2))\n",
        "      result.append(i)\n",
        "  return result"
      ],
      "metadata": {
        "id": "RzCzNooJtTEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JbkuUpWjuGf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conditional_probability(X,Y,Z, x_value, y_value, z_value):\n",
        "  \"\"\"\n",
        "  Calculates the conditional probability of X given Y and Z.\n",
        "\n",
        "  Args:\n",
        "      data (pd.DataFrame): A DataFrame containing three columns: 'X', 'Y', and 'Z'.\n",
        "      x_value: The value of X for which to calculate the probability.\n",
        "      y_value: The value of Y to condition on.\n",
        "      z_value: The value of Z to condition on.\n",
        "\n",
        "  Returns:\n",
        "      float: The conditional probability of X given Y and Z.\n",
        "  \"\"\"\n",
        "  data = pd.DataFrame({'X':X, 'Y': Y, 'Z': Z})\n",
        "\n",
        "  # Filter data for specific Y and Z values\n",
        "  filtered_data = data[(data['Y'] == y_value) & (data['Z'] == z_value)]\n",
        "\n",
        "  # Check if there are any matching Y and Z values\n",
        "  if filtered_data.empty:\n",
        "    return 0\n",
        "\n",
        "  # Calculate the probability of X given Y and Z\n",
        "  probability = (filtered_data['X'] == x_value).mean()\n",
        "  return probability\n"
      ],
      "metadata": {
        "id": "P6PxHuq9IPxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_correlation_table_weights_local(n, t_c, t_w, r,s):\n",
        "    \"\"\"\n",
        "    Generates a table of Dual Total Correlations for different correlation coefficients.\n",
        "\n",
        "    Args:\n",
        "        n (int): Number of samples in X1 and X2.\n",
        "        t (int): Number of entries in the table.\n",
        "        r (int): Range for the values in X1 and X2 (0 to r).\n",
        "        s=seed\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame: A table containing correlation coefficients, X1-X2\n",
        "                          correlations, and Dual Total Correlations.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    corrs = np.linspace(0, 1, t_c)  # Uniformly spaced correlation coefficients\n",
        "    weights= np.linspace(0, 1, t_w)\n",
        "    results = []\n",
        "    for w_AND in weights:\n",
        "      print(w_AND)\n",
        "      for corr in corrs:\n",
        "        X1, X2 = create_correlated_datasets(n, r, s, corr)\n",
        "        Y=w_AND*np.logical_and(X1,X2)+(1-w_AND)*np.logical_xor(X1,X2)\n",
        "        Y=Y.round()\n",
        "        #Y=np.random.randint(0, r + 1, size=n)\n",
        "\n",
        "        true_corr = np.corrcoef(X1, X2)[0, 1]  # True correlation between X1 and X2\n",
        "        X1_Y_corr=np.corrcoef(X1, Y)[0, 1]\n",
        "        X2_Y_corr=np.corrcoef(X2, Y)[0, 1]\n",
        "        dtc = DTC_List_continuous(X1, X2, Y)\n",
        "        tc= TC_List_continuous(X1,X2,Y)\n",
        "        tc_local=local_TC(X1,X2,Y)\n",
        "        dtc_local=local_DTC(X1,X2,Y)\n",
        "\n",
        "        results.append({'w_AND': w_AND, 'X1-X2 Correlation': true_corr, 'X1-Y Correlation': X1_Y_corr,'X2-Y Correlation': X2_Y_corr,'DTC': dtc, 'DTC_AVG': np.mean(dtc_local),'DTC_MED': np.median(dtc_local), 'DTC_Q1': np.percentile(dtc_local,25), 'DTC_Q3': np.percentile(dtc_local,75), 'TC': tc, 'TC_AVG': np.mean(tc_local),'TC_MED': np.median(tc_local),'TC_Q1': np.percentile(tc_local,25), 'TC_Q3': np.percentile(tc_local,75),  'OINF': tc-dtc, 'TC_STDV': np.std(tc_local), 'DTC_STDV': np.std(dtc_local), 'DTC_LOCAL': dtc_local, 'TC_LOCAL': tc_local, 'TC_SET': set(tc_local), 'DTC_SET':set(dtc_local) })\n",
        "    df = pd.DataFrame(results)\n",
        "\n",
        "\n",
        "\n",
        "    return pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "rSzckQ3TM8o-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_correlation_table_function(n, t_c, r,s,f):\n",
        "    \"\"\"\n",
        "    Generates a table of Dual Total Correlations for different correlation coefficients.\n",
        "\n",
        "    Args:\n",
        "        n (int): Number of samples in X1 and X2.\n",
        "        t_c (int): Number of correlation values\n",
        "        r (int): Range for the values in X1 and X2 (0 to r).\n",
        "        s=seed\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame: A table containing correlation coefficients, X1-X2\n",
        "                          correlations, and Dual Total Correlations.\n",
        "    \"\"\"\n",
        "\n",
        "    print(f)\n",
        "    corrs = np.linspace(0, 1, t_c)  # Uniformly spaced correlation coefficients\n",
        "    results = []\n",
        "    for corr in corrs:\n",
        "        print(\"NEXT EXPERIMENT\")\n",
        "        print(f\"corr X1_X2={corr:.2f}\")\n",
        "        X1, X2 = create_correlated_binary_datasets(n, s, corr)\n",
        "        true_corr = np.corrcoef(X1, X2)[0, 1]  # True correlation between X1 and X2\n",
        "        print(f\"true_corr X1_X2={true_corr:.2f}\")\n",
        "        if f==1:\n",
        "          Y=np.logical_and(X1,X2)\n",
        "        if f==2:\n",
        "          Y=np.logical_xor(X1,X2)\n",
        "        if f==3:\n",
        "          Y=np.random.randint(0, r + 1, size=n)\n",
        "        if f==4:\n",
        "          Y=X1\n",
        "        Y=np.clip(Y, 0, 1).round()\n",
        "\n",
        "\n",
        "        X1_Y_corr=np.corrcoef(X1, Y)[0, 1]\n",
        "        X2_Y_corr=np.corrcoef(X2, Y)[0, 1]\n",
        "        dtc = DTC_List_continuous(X1, X2, Y)\n",
        "        tc= TC_List_continuous(X1,X2,Y)\n",
        "        mi=mutual_informationX1X2Y(X1, X2, Y)\n",
        "        tc_local=local_TC(X1,X2,Y)\n",
        "        dtc_local=local_DTC(X1,X2,Y)\n",
        "        o_local=[a - b for a, b in zip(tc_local, dtc_local)]\n",
        "        mi_local=local_mutual_X1X2Y(X1,X2,Y)\n",
        "\n",
        "        results.append({'X1': X1, 'X2': X2, 'Y':Y, 'X1-X2 Correlation': true_corr, 'X1-Y Correlation': X1_Y_corr,'X2-Y Correlation': X2_Y_corr,'DTC': dtc, 'DTC_AVG': np.mean(dtc_local),'DTC_MED': np.median(dtc_local), 'DTC_Q1': np.percentile(dtc_local,25), 'DTC_Q3': np.percentile(dtc_local,75), 'TC': tc, 'TC_AVG': np.mean(tc_local),'TC_MED': np.median(tc_local),'TC_Q1': np.percentile(tc_local,25), 'TC_Q3': np.percentile(tc_local,75),  'OINF': tc-dtc, 'OINF_LOCAL': o_local, 'TC_STDV': np.std(tc_local), 'DTC_STDV': np.std(dtc_local), 'DTC_LOCAL': dtc_local, 'TC_LOCAL': tc_local, 'TC_SET': set(tc_local), 'DTC_SET':set(dtc_local), 'OINF_SET':set(o_local), 'MUTUAL_INF':mi, 'MI_LOCAL': mi_local, 'MI_SET':set(mi_local) })\n",
        "        data = {\n",
        "          'X1': X1,\n",
        "          'X2': X2,\n",
        "          'Y': Y,\n",
        "          'tc_local': tc_local,\n",
        "          'dtc_local': dtc_local,\n",
        "          'mi_local': mi_local\n",
        "        }\n",
        "        df_overview=analyze_dataframe(pd.DataFrame(data))\n",
        "        print(df_overview)\n",
        "        print(\"TC=\", f\"{tc:.2f}\")\n",
        "        print(\"DTC=\", f\"{dtc:.2f}\")\n",
        "        print(\"O_INF=\", f\"{tc-dtc:.2f}\")\n",
        "        print(\"MUTUAL INF=\", f\"{mi:.2f}\")\n",
        "        print(\"\\n\\n\")\n",
        "        #bubble_plot(df_overview)\n",
        "\n",
        "    return pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "D-j2ccZ45vCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_correlation_vs_dtc_tc_spread(df, figsize=(10, 4)):\n",
        "  \"\"\"\n",
        "  Creates plots with two subplots: 'X1-X2 Correlation' vs 'DTC' and\n",
        "  'X1-X2 Correlation' vs 'TC' for each w_AND value. Ensures shared y-axis range.\n",
        "\n",
        "  Args:\n",
        "      df (pandas.DataFrame): The DataFrame containing results.\n",
        "      figsize (tuple, optional): The size of each figure. Defaults to (10, 4).\n",
        "      marker_color (str, optional): The color for all markers. Defaults to 'red'.\n",
        "  \"\"\"\n",
        "  ylim_min = -5\n",
        "  ylim_max = 5\n",
        "\n",
        "  for i, group in df.groupby('w_AND'):\n",
        "    w_AND = group['w_AND'].iloc[0]\n",
        "    title = f\"w_AND = {w_AND}\"  # Create title string with w_AND value\n",
        "\n",
        "    # Create figure and subplots\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n",
        "\n",
        "    # Add title to each subplot\n",
        "    ax1.set_title(title)\n",
        "    ax2.set_title(title)\n",
        "\n",
        "    for index, row in group.iterrows():\n",
        "      x_value = row['X1-X2 Correlation']\n",
        "      y_values = row['DTC_SET']\n",
        "      for y in y_values:\n",
        "        ax1.scatter(x_value, y, color='blue')  # Set marker color\n",
        "      ax1.scatter(x_value, row['DTC'], color='red')\n",
        "\n",
        "    # Plot 'X1-X2 Correlation' vs 'TC'\n",
        "    for index, row in group.iterrows():\n",
        "      x_value = row['X1-X2 Correlation']\n",
        "      y_values = row['TC_SET']\n",
        "      for y in y_values:\n",
        "        ax2.scatter(x_value, y, color='blue')  # Set marker color\n",
        "      ax2.scatter(x_value, row['TC'], color='red')\n",
        "\n",
        "\n",
        "    # Set the same y-axis range for both subplots\n",
        "    #ax1.set_ylim(ylim_min, ylim_max)\n",
        "    #ax2.set_ylim(ylim_min, ylim_max)\n",
        "\n",
        "    # Add axis labels\n",
        "    ax1.set_xlabel('X1-X2 Correlation')\n",
        "    ax1.set_ylabel('DTC')\n",
        "    ax2.set_xlabel('X1-X2 Correlation')\n",
        "    ax2.set_ylabel('TC')\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "OW-hafUa6D4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_correlation_vs_dtc_tc_oinf_mi_spread_function(df, figsize=(25, 4)):\n",
        "  \"\"\"\n",
        "  Creates plots with two subplots: 'X1-X2 Correlation' vs 'DTC' and\n",
        "  'X1-X2 Correlation' vs 'TC' for each w_AND value. Ensures shared y-axis range.\n",
        "\n",
        "  Args:\n",
        "      df (pandas.DataFrame): The DataFrame containing results.\n",
        "      figsize (tuple, optional): The size of each figure. Defaults to (10, 4).\n",
        "      marker_color (str, optional): The color for all markers. Defaults to 'red'.\n",
        "  \"\"\"\n",
        "  ylim_min = -5\n",
        "  ylim_max = 5\n",
        "\n",
        "  # Create figure and subplots\n",
        "  fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=figsize)\n",
        "\n",
        "  # Add title to each subplot\n",
        "  ax1.set_title(\"DTC\")\n",
        "  ax2.set_title(\"TC\")\n",
        "  ax3.set_title(\"OINF\")\n",
        "  ax4.set_title(\"MUTUAL INF\")\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "    x_value = row['X1-X2 Correlation']\n",
        "    y_values = row['DTC_SET']\n",
        "    for y in y_values:\n",
        "      ax1.scatter(x_value, y, color='blue')  # Set marker color\n",
        "    ax1.scatter(x_value, row['DTC'], color='red')\n",
        "\n",
        "  # Plot 'X1-X2 Correlation' vs 'TC'\n",
        "  for index, row in df.iterrows():\n",
        "    x_value = row['X1-X2 Correlation']\n",
        "    y_values = row['TC_SET']\n",
        "    for y in y_values:\n",
        "      ax2.scatter(x_value, y, color='blue')  # Set marker color\n",
        "    ax2.scatter(x_value, row['TC'], color='red')\n",
        "\n",
        "  # Plot 'X1-X2 Correlation' vs 'O-INFO'\n",
        "  for index, row in df.iterrows():\n",
        "    x_value = row['X1-X2 Correlation']\n",
        "    y_values = row['OINF_SET']\n",
        "    for y in y_values:\n",
        "      ax3.scatter(x_value, y, color='blue')  # Set marker color\n",
        "    ax3.scatter(x_value, row['OINF'], color='red')\n",
        "\n",
        "   # Plot 'X1-X2 Correlation' vs 'O-INFO'\n",
        "  for index, row in df.iterrows():\n",
        "    x_value = row['X1-X2 Correlation']\n",
        "    y_values = row['MI_SET']\n",
        "    for y in y_values:\n",
        "      ax4.scatter(x_value, y, color='blue')  # Set marker color\n",
        "    ax4.scatter(x_value, row['MUTUAL_INF'], color='red')\n",
        "\n",
        "    # Set the same y-axis range for both subplots\n",
        "    #ax1.set_ylim(ylim_min, ylim_max)\n",
        "    #ax2.set_ylim(ylim_min, ylim_max)\n",
        "\n",
        "    # Add axis labels\n",
        "    ax1.set_xlabel('X1-X2 Correlation')\n",
        "    ax1.set_ylabel('DTC')\n",
        "    ax2.set_xlabel('X1-X2 Correlation')\n",
        "    ax2.set_ylabel('TC')\n",
        "    ax3.set_xlabel('X1-X2 Correlation')\n",
        "    ax3.set_ylabel('O-INF')\n",
        "    ax4.set_xlabel('X1-X2 Correlation')\n",
        "    ax4.set_ylabel('MUTUAL INF')\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "FDIuVgxq60PX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_dataframe(df_data):\n",
        "  \"\"\"\n",
        "  Analyzes a DataFrame containing features X1, X2, Y, tc_local, and dtc_local,\n",
        "  calculates descriptive statistics for each unique combination,\n",
        "  and returns a new DataFrame with the results, formatting tc_local and dtc_local to 2 decimals.\n",
        "\n",
        "  Args:\n",
        "      df_data (pandas.DataFrame): The DataFrame containing the data.\n",
        "\n",
        "  Returns:\n",
        "      pandas.DataFrame: A new DataFrame with the following columns, formatted as specified:\n",
        "          - X1/X2/Y: Unique combination of features.\n",
        "          - Count (%): Percentage occurrence of the combination (normalized).\n",
        "          - tc_local: Average value of tc_local for the combination, formatted to 2 decimals.\n",
        "          - dtc_local: Average value of dtc_local for the combination, formatted to 2 decimals.\n",
        "  \"\"\"\n",
        "\n",
        "  # Group by X1, X2, and Y for efficient calculations\n",
        "  grouped_data = df_data.groupby(['X1', 'X2', 'Y'])\n",
        "\n",
        "  # Calculate descriptive statistics with appropriate functions\n",
        "  results = grouped_data.agg(\n",
        "      Count=('X1', 'size'),  # Count occurrences (faster than nrows)\n",
        "      tc_local=('tc_local', 'mean'),\n",
        "      dtc_local=('dtc_local', 'mean'),\n",
        "      mi_local=('mi_local', 'mean')\n",
        "  ).reset_index()\n",
        "\n",
        "  # Normalize Count to percentage\n",
        "  results['Count (%)'] = (results['Count'] / len(df_data)) * 100\n",
        "\n",
        "  # Custom formatting function for string representation (2 decimals)\n",
        "  def format_two_decimals(value):\n",
        "      return f\"{value:.2f}\"\n",
        "\n",
        "  # Format tc_local and dtc_local columns using list comprehension\n",
        "  results[['tc_local', 'dtc_local', 'mi_local']] = results[['tc_local', 'dtc_local', 'mi_local']].applymap(format_two_decimals)\n",
        "\n",
        "  # Reorder columns as requested\n",
        "  results = results[['X1', 'X2', 'Y', 'Count (%)', 'tc_local', 'dtc_local', 'mi_local']]\n",
        "\n",
        "  # Print the DataFrame with clear column titles for readability\n",
        "  print(\"Analysis Results:\")\n",
        "  #print(results)\n",
        "\n",
        "  return results"
      ],
      "metadata": {
        "id": "_xUmSgbGYxYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bubble_plot(results):\n",
        "  \"\"\"\n",
        "  Creates a bubble chart with numerically ordered axes and bubble sizes proportional to count(%).\n",
        "\n",
        "  Args:\n",
        "      results (pandas.DataFrame): The DataFrame containing the results.\n",
        "  \"\"\"\n",
        "\n",
        "  # Extract data for plotting and ensure numerical interpretation\n",
        "  tc_local = results['tc_local'].astype(float)  # Explicitly cast to float\n",
        "  dtc_local = results['dtc_local'].astype(float)  # Explicitly cast to float\n",
        "  count_percent = results['Count (%)'] * 10  # Adjust bubble size based on count percentage\n",
        "\n",
        "  # Sort data for numerically ordered axes\n",
        "  sorted_data = results[['tc_local', 'dtc_local', 'Count (%)']].sort_values(by=['tc_local', 'dtc_local'])\n",
        "  sorted_tc_local = sorted_data['tc_local'].to_numpy()\n",
        "  sorted_dtc_local = sorted_data['dtc_local'].to_numpy()\n",
        "  sorted_count_percent = sorted_data['Count (%)'].to_numpy()\n",
        "\n",
        "  # Create the bubble chart\n",
        "  plt.figure(figsize=(8, 6))  # Set figure size for readability\n",
        "  plt.scatter(sorted_tc_local, sorted_dtc_local, s=sorted_count_percent, alpha=0.7, edgecolors='k')  # Customize plot\n",
        "\n",
        "  # Add labels and title\n",
        "  plt.xlabel('tc_local (average)')\n",
        "  plt.ylabel('dtc_local (average)')\n",
        "  plt.title('Bubble Chart of tc_local vs. dtc_local (Bubble Size Proportional to Count %)')\n",
        "\n",
        "  # Ensure numerical ordering on axes\n",
        "  plt.xticks(rotation=45)  # Rotate x-axis labels for readability if needed\n",
        "  plt.yticks()\n",
        "\n",
        "  # Show the plot\n",
        "  plt.show()\n",
        "\n",
        "  return results"
      ],
      "metadata": {
        "id": "yolz4vfhl50z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_local_distributions(df_overview, w_AND, corr):\n",
        "  \"\"\"\n",
        "  This function plots the distributions of tc_local and dtc_local from the given DataFrame.\n",
        "\n",
        "  Args:\n",
        "      df_overview (pandas.DataFrame): A DataFrame containing tc_local and occurence columns.\n",
        "  \"\"\"\n",
        "\n",
        "  # Set bar width (adjust as needed)\n",
        "  bar_width = 0.01\n",
        "  tc_avg= (df_overview[\"tc_local\"] * df_overview[\"occurence\"]).sum()\n",
        "  dtc_avg=(df_overview[\"dtc_local\"] * df_overview[\"occurence\"]).sum()\n",
        "  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))  # Adjust figure size for better readability\n",
        "\n",
        "  # Plot tc_local distribution as bars\n",
        "  ax2.bar(df_overview[\"tc_local\"], df_overview[\"occurence\"], width=bar_width, color='green', label='TC_local')\n",
        "  ax2.plot( [tc_avg, tc_avg],[0, 0.5],color='red', label='TC=Average')  # Add average marker with label\n",
        "\n",
        "\n",
        "  # Plot dtc_local distribution as bars\n",
        "  ax1.bar(df_overview[\"dtc_local\"], df_overview[\"occurence\"], width=bar_width, color='green', label='DTC_local')\n",
        "  ax1.plot( [dtc_avg, dtc_avg],[0, 0.5],color='red', label='DTC=Average')  # Add average marker with label\n",
        "\n",
        "\n",
        "  # Add titles and labels\n",
        "  ax2.set_title(f'TC:  w_AND = {w_AND:.2f}, X1_X2_Corr={corr}')\n",
        "  ax1.set_title(f'DTC: w_AND = {w_AND:.2f}, X1_X2_Corr={corr}')\n",
        "  ax2.set_xlabel('TC_LOCAL')\n",
        "  ax1.set_xlabel('DTC_LOCAL')\n",
        "  ax2.set_ylabel('OCCURENCE')\n",
        "  ax1.set_ylabel('OCCURENCE')\n",
        "\n",
        "  # Add legend (optional)\n",
        "  ax1.legend()\n",
        "  ax2.legend()\n",
        "\n",
        "  plt.tight_layout()  # Adjust spacing for better readability\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "hmhCXsYQpU0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n= 400\n",
        "t_c=20\n",
        "r=1"
      ],
      "metadata": {
        "id": "3MiZKP6PjP1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=generate_correlation_table_function(n, t_c, r,s,1)\n",
        "plot_correlation_vs_dtc_tc_oinf_mi_spread_function(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlMjXwh9jMLb",
        "outputId": "96542011-a736-40ba-8d3e-62aa9b1178cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "NEXT EXPERIMENT\n",
            "corr X1_X2=0.00\n",
            "true_corr X1_X2=0.02\n",
            "Analysis Results:\n",
            "   X1  X2  Y  Count (%) tc_local dtc_local mi_local\n",
            "0   0   0  0      28.00     0.41      0.03     0.38\n",
            "1   0   1  0      22.50     0.34      0.99     0.38\n",
            "2   1   0  0      26.25     0.35      0.88     0.38\n",
            "3   1   1  1      23.25     2.14      2.10     2.10\n",
            "TC= 0.78\n",
            "DTC= 0.95\n",
            "O_INF= -0.17\n",
            "MUTUAL INF= 0.78\n",
            "\n",
            "\n",
            "\n",
            "NEXT EXPERIMENT\n",
            "corr X1_X2=0.05\n",
            "true_corr X1_X2=0.11\n",
            "Analysis Results:\n",
            "   X1  X2  Y  Count (%) tc_local dtc_local mi_local\n",
            "0   0   0  0       27.0     0.64      0.16     0.48\n",
            "1   0   1  0       24.5     0.33      0.96     0.48\n",
            "2   1   0  0       20.0     0.30      1.09     0.48\n",
            "3   1   1  1       28.5     1.96      1.81     1.81\n",
            "TC= 0.87\n",
            "DTC= 1.01\n",
            "O_INF= -0.14\n",
            "MUTUAL INF= 0.86\n",
            "\n",
            "\n",
            "\n",
            "NEXT EXPERIMENT\n",
            "corr X1_X2=0.11\n",
            "true_corr X1_X2=0.15\n",
            "Analysis Results:\n",
            "   X1  X2  Y  Count (%) tc_local dtc_local mi_local\n",
            "0   0   0  0      27.75     0.72      0.21     0.51\n",
            "1   0   1  0      23.25     0.29      0.97     0.51\n",
            "2   1   0  0      19.25     0.25      1.09     0.51\n",
            "3   1   1  1      29.75     1.95      1.75     1.75\n",
            "TC= 0.89\n",
            "DTC= 1.01\n",
            "O_INF= -0.12\n",
            "MUTUAL INF= 0.88\n",
            "\n",
            "\n",
            "\n",
            "NEXT EXPERIMENT\n",
            "corr X1_X2=0.16\n",
            "true_corr X1_X2=0.19\n",
            "Analysis Results:\n",
            "   X1  X2  Y  Count (%) tc_local dtc_local mi_local\n",
            "0   0   0  0      28.50     0.79      0.26     0.53\n",
            "1   0   1  0      22.25     0.26      0.98     0.53\n",
            "2   1   0  0      18.50     0.21      1.09     0.53\n",
            "3   1   1  1      30.75     1.94      1.70     1.70\n",
            "TC= 0.92\n",
            "DTC= 1.02\n",
            "O_INF= -0.10\n",
            "MUTUAL INF= 0.89\n",
            "\n",
            "\n",
            "\n",
            "NEXT EXPERIMENT\n",
            "corr X1_X2=0.21\n",
            "true_corr X1_X2=0.22\n",
            "Analysis Results:\n",
            "   X1  X2  Y  Count (%) tc_local dtc_local mi_local\n",
            "0   0   0  0      29.25     0.84      0.29     0.55\n",
            "1   0   1  0      21.25     0.22      0.99     0.55\n",
            "2   1   0  0      18.00     0.17      1.08     0.55\n",
            "3   1   1  1      31.50     1.94      1.67     1.67\n",
            "TC= 0.93\n",
            "DTC= 1.02\n",
            "O_INF= -0.08\n",
            "MUTUAL INF= 0.90\n",
            "\n",
            "\n",
            "\n",
            "NEXT EXPERIMENT\n",
            "corr X1_X2=0.26\n",
            "true_corr X1_X2=0.26\n",
            "Analysis Results:\n",
            "   X1  X2  Y  Count (%) tc_local dtc_local mi_local\n",
            "0   0   0  0      30.25     0.91      0.34     0.57\n",
            "1   0   1  0      19.75     0.16      1.00     0.57\n",
            "2   1   0  0      17.50     0.12      1.07     0.57\n",
            "3   1   1  1      32.50     1.94      1.62     1.62\n",
            "TC= 0.96\n",
            "DTC= 1.01\n",
            "O_INF= -0.06\n",
            "MUTUAL INF= 0.91\n",
            "\n",
            "\n",
            "\n",
            "NEXT EXPERIMENT\n",
            "corr X1_X2=0.32\n",
            "true_corr X1_X2=0.30\n",
            "Analysis Results:\n",
            "   X1  X2  Y  Count (%) tc_local dtc_local mi_local\n",
            "0   0   0  0       31.5     0.98      0.39     0.59\n",
            "1   0   1  0       18.5     0.10      1.00     0.59\n",
            "2   1   0  0       16.5     0.05      1.06     0.59\n",
            "3   1   1  1       33.5     1.94      1.58     1.58\n",
            "TC= 0.99\n",
            "DTC= 1.01\n",
            "O_INF= -0.03\n",
            "MUTUAL INF= 0.92\n",
            "\n",
            "\n",
            "\n",
            "NEXT EXPERIMENT\n",
            "corr X1_X2=0.37\n",
            "true_corr X1_X2=0.34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=generate_correlation_table_function(n, t_c, r,s,2)\n",
        "plot_correlation_vs_dtc_tc_oinf_mi_spread_function(df)"
      ],
      "metadata": {
        "id": "M3kSm65MjXi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=generate_correlation_table_function(n, t_c, r,s,3)\n",
        "plot_correlation_vs_dtc_tc_oinf_mi_spread_function(df)"
      ],
      "metadata": {
        "id": "80J8al4vjbtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=generate_correlation_table_function(n, t_c, r,s,4)\n",
        "plot_correlation_vs_dtc_tc_oinf_mi_spread_function(df)"
      ],
      "metadata": {
        "id": "l8s50xnTjdLf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}